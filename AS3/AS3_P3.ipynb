{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEH1QQShWeaG"
      },
      "source": [
        "CS512 - Computer Vision - Assignment 3 - S3\n",
        "\n",
        "Submitted by-\n",
        "\n",
        "Tushar Gwal A20449419"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCdzybGxVC63"
      },
      "source": [
        "# Part 1: Dataset Loading through Pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R3q1FoOLMaz"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Function to unpickle the dataset\n",
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')  #refeered from Cifar\n",
        "    return dict\n",
        "\n",
        "# Loading all CIFAR-10 batches\n",
        "db_1 = unpickle(r\"/content/data_batch_1\")\n",
        "db_2 = unpickle(r\"/content/data_batch_2\")\n",
        "db_3 = unpickle(r\"/content/data_batch_3\")\n",
        "db_4 = unpickle(r\"/content/data_batch_4\")\n",
        "db_5 = unpickle(r\"/content/data_batch_5\")\n",
        "\n",
        "# Extracting data and labels from batches\n",
        "def load_batch(data_batch):\n",
        "    x = data_batch[b'data']\n",
        "    Y = np.array(data_batch[b'labels'])\n",
        "    x = x.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Reshape and transpose to (32, 32, 3)\n",
        "    return x, Y\n",
        "\n",
        "# Loading each batch\n",
        "xt_1, Yt_1 = load_batch(db_1)\n",
        "xt_2, Yt_2 = load_batch(db_2)\n",
        "xt_3, Yt_3 = load_batch(db_3)\n",
        "xt_4, Yt_4 = load_batch(db_4)\n",
        "xt_5, Yt_5 = load_batch(db_5)\n",
        "\n",
        "# Combining the data into a single training set\n",
        "x_train = np.concatenate([xt_1, xt_2, xt_3, xt_4, xt_5], axis=0)\n",
        "Y_train = np.concatenate([Yt_1, Yt_2, Yt_3, Yt_4, Yt_5], axis=0)\n",
        "\n",
        "# Loading the test batch\n",
        "tb = unpickle(r\"/content/test_batch\")\n",
        "x_test, Y_test = load_batch(tb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI_66vNWNW6o"
      },
      "source": [
        "# Preprossing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esrCa6LUZJXG"
      },
      "outputs": [],
      "source": [
        "# Normalize pixel values between 0 and 1\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255\n",
        "\n",
        "# Spliting training data into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, Y_train, Y_val = train_test_split(x_train, Y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Converting labels to categorical (one-hot encoding)\n",
        "import tensorflow as tf\n",
        "Y_train =tf.keras.utils.to_categorical(Y_train, 10)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, 10)\n",
        "Y_val = tf.keras.utils.to_categorical(Y_val, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsIOU_oHO6j3"
      },
      "source": [
        "#Part 2: Building the basic CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNeXaxCTPDqP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, BatchNormalization # Import layers from tensorflow.keras.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "LEiiHrf9QOrF",
        "outputId": "3ba058ac-c628-4692-f0f9-5a0a04e568ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m1,568\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m32,832\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m131,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,570\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,194</span> (785.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m201,194\u001b[0m (785.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,194</span> (785.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m201,194\u001b[0m (785.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "## FIRST SET OF LAYERS\n",
        "\n",
        "# CONVOLUTIONAL LAYER\n",
        "model.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(32, 32, 3), activation='relu',))\n",
        "# POOLING LAYER\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# Normailzation layer\n",
        "BatchNormalization()\n",
        "\n",
        "## SECOND SET OF LAYERS\n",
        "\n",
        "# CONVOLUTIONAL LAYER\n",
        "model.add(Conv2D(filters=64, kernel_size=(4,4),input_shape=(32, 32, 3), activation='relu',))\n",
        "# POOLING LAYER\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# Normailzation layer\n",
        "BatchNormalization()\n",
        "\n",
        "## Third SET OF LAYERS\n",
        "\n",
        "# CONVOLUTIONAL LAYER\n",
        "model.add(Conv2D(filters=128, kernel_size=(4,4),input_shape=(32, 32, 3), activation='relu',))\n",
        "# POOLING LAYER\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# Normailzation layer\n",
        "BatchNormalization()\n",
        "\n",
        "# FLATTEN IMAGES FROM 28 by 28 to 764 BEFORE FINAL LAYER\n",
        "model.add(Flatten())\n",
        "\n",
        "# 256 NEURONS IN DENSE HIDDEN LAYER\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# LAST LAYER IS THE CLASSIFIER, THUS 10 POSSIBLE CLASSES\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjpWPKZHTC9K",
        "outputId": "1bc00bd8-79ee-4bb6-da0e-dbc9530d2926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 59ms/step - accuracy: 0.3090 - loss: 1.8707 - val_accuracy: 0.5356 - val_loss: 1.3063\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 58ms/step - accuracy: 0.5496 - loss: 1.2602 - val_accuracy: 0.6062 - val_loss: 1.1249\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 59ms/step - accuracy: 0.6334 - loss: 1.0420 - val_accuracy: 0.6376 - val_loss: 1.0269\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 59ms/step - accuracy: 0.6835 - loss: 0.9050 - val_accuracy: 0.6600 - val_loss: 0.9870\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 60ms/step - accuracy: 0.7239 - loss: 0.7935 - val_accuracy: 0.6480 - val_loss: 1.0600\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 60ms/step - accuracy: 0.7528 - loss: 0.7187 - val_accuracy: 0.6773 - val_loss: 0.9783\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 57ms/step - accuracy: 0.7784 - loss: 0.6499 - val_accuracy: 0.6599 - val_loss: 1.1120\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 56ms/step - accuracy: 0.8005 - loss: 0.5784 - val_accuracy: 0.6863 - val_loss: 1.0351\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 57ms/step - accuracy: 0.8153 - loss: 0.5401 - val_accuracy: 0.6696 - val_loss: 1.1238\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 59ms/step - accuracy: 0.8256 - loss: 0.5115 - val_accuracy: 0.6763 - val_loss: 1.2261\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cd55e1785e0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train,Y_train,verbose=1,epochs=10,validation_data=(x_val,Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G4n4wk9XnpFr",
        "outputId": "e53cf354-2dc6-4c82-9e23-5ed5fd0bbbd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.6776 - loss: 1.2430\n",
            "Test Accuracy for basic CNN model: 67.30%\n",
            "Test Loss for basic CNN model: 1.2543\n"
          ]
        }
      ],
      "source": [
        "t_loss, t_acc = model.evaluate(x_test,Y_test)\n",
        "print(f\"Test Accuracy for basic CNN model: {t_acc * 100:.2f}%\")\n",
        "print(f\"Test Loss for basic CNN model: {t_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x06mTWiJncb0"
      },
      "source": [
        "# Part 3: Replacing the convolution block with inception block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nZWnJUOnpLz",
        "outputId": "07e1bf49-08ab-48d9-dc4f-212e245655e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 327ms/step - accuracy: 0.5001 - loss: 1.4272 - val_accuracy: 0.6507 - val_loss: 1.0078\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 326ms/step - accuracy: 0.6931 - loss: 0.8692 - val_accuracy: 0.6912 - val_loss: 0.8793\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 310ms/step - accuracy: 0.7588 - loss: 0.7019 - val_accuracy: 0.7278 - val_loss: 0.7874\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 312ms/step - accuracy: 0.7967 - loss: 0.5895 - val_accuracy: 0.7461 - val_loss: 0.7312\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 331ms/step - accuracy: 0.8441 - loss: 0.4478 - val_accuracy: 0.7322 - val_loss: 0.8474\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 332ms/step - accuracy: 0.8748 - loss: 0.3586 - val_accuracy: 0.7327 - val_loss: 0.8727\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 301ms/step - accuracy: 0.9093 - loss: 0.2640 - val_accuracy: 0.7588 - val_loss: 0.8293\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 304ms/step - accuracy: 0.9340 - loss: 0.1924 - val_accuracy: 0.7284 - val_loss: 0.9679\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 302ms/step - accuracy: 0.9512 - loss: 0.1419 - val_accuracy: 0.7678 - val_loss: 0.9038\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 308ms/step - accuracy: 0.9578 - loss: 0.1231 - val_accuracy: 0.7323 - val_loss: 1.1172\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cd5542e7b20>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "#Lets create an Inception block\n",
        "in_layer = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "# 1x1 Convolution\n",
        "branch1x1 = layers.Conv2D(32, (1, 1), padding='same', activation='relu')(in_layer)\n",
        "\n",
        "# 1x1 Convolution followed by 3x3 Convolution\n",
        "branch3x3 = layers.Conv2D(32, (1, 1), padding='same', activation='relu')(in_layer)\n",
        "branch3x3 = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(branch3x3)\n",
        "\n",
        "# 1x1 Convolution followed by 5x5 Convolution\n",
        "branch5x5 = layers.Conv2D(16, (1, 1), padding='same', activation='relu')(in_layer)\n",
        "branch5x5 = layers.Conv2D(32, (5, 5), padding='same', activation='relu')(branch5x5)\n",
        "\n",
        "# 3x3 MaxPooling followed by 1x1 Convolution\n",
        "branch_pool = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(in_layer)\n",
        "branch_pool = layers.Conv2D(32, (1, 1), padding='same', activation='relu')(branch_pool)\n",
        "\n",
        "# Concatenate all branches\n",
        "x = layers.concatenate([branch1x1, branch3x3, branch5x5, branch_pool])\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Flatten()(x)\n",
        "output_layer = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Creating the Inception model\n",
        "m2 = models.Model(inputs=in_layer, outputs=output_layer)\n",
        "\n",
        "# Compiling the model\n",
        "m2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "m2.fit(x_train, Y_train, epochs=10, validation_data=(x_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_sXY3KuCAHR",
        "outputId": "e79c37e0-d623-430f-b2ac-2c22f2209655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 85ms/step - accuracy: 0.7260 - loss: 1.1615\n",
            "Test Accuracy for Inception Model : 72.36%\n",
            "Test Loss for Inception Model: 1.1665\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the Inception model\n",
        "t_loss, t_acc = m2.evaluate(x_test, Y_test)\n",
        "print(f\"Test Accuracy for Inception Model : {t_acc * 100:.2f}%\")\n",
        "print(f\"Test Loss for Inception Model: {t_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC6QHzezvKvL"
      },
      "source": [
        "# Part 4: Building CNN model with Residual Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm936LWavLCY",
        "outputId": "01381862-9211-4ba9-b2e6-fac4dfe27d1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 386ms/step - accuracy: 0.4659 - loss: 1.6379 - val_accuracy: 0.6789 - val_loss: 0.9421\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 385ms/step - accuracy: 0.7163 - loss: 0.8206 - val_accuracy: 0.6042 - val_loss: 1.2768\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 363ms/step - accuracy: 0.7858 - loss: 0.6115 - val_accuracy: 0.7096 - val_loss: 0.8549\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 390ms/step - accuracy: 0.8406 - loss: 0.4570 - val_accuracy: 0.7113 - val_loss: 0.8880\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 390ms/step - accuracy: 0.8827 - loss: 0.3369 - val_accuracy: 0.7444 - val_loss: 0.7990\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 391ms/step - accuracy: 0.9184 - loss: 0.2357 - val_accuracy: 0.7650 - val_loss: 0.8456\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 391ms/step - accuracy: 0.9402 - loss: 0.1709 - val_accuracy: 0.7266 - val_loss: 0.9684\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 404ms/step - accuracy: 0.9557 - loss: 0.1313 - val_accuracy: 0.7614 - val_loss: 0.9697\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 393ms/step - accuracy: 0.9662 - loss: 0.0998 - val_accuracy: 0.7568 - val_loss: 1.0101\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 394ms/step - accuracy: 0.9677 - loss: 0.0900 - val_accuracy: 0.7557 - val_loss: 1.0671\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cd554a4bf10>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a Residual block\n",
        "in_layer = layers.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(in_layer)\n",
        "\n",
        "# First set of layers\n",
        "shortcut = x\n",
        "x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Add()([x, shortcut])\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Second sets of layer\n",
        "shortcut = x\n",
        "# Applying 1x1 convolution to match the number of channels\n",
        "shortcut = layers.Conv2D(64, (1, 1), padding='same')(shortcut) # Adjusting the shortcut to have 64 channels\n",
        "x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Add()([x, shortcut])\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Third sets of layer\n",
        "shortcut = x\n",
        "# Applying 1x1 convolution to match the number of channels\n",
        "shortcut = layers.Conv2D(128, (1, 1), padding='same')(shortcut) # Adjusting the shortcut to have 128 channels\n",
        "x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Add()([x, shortcut])\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Flatten()(x)\n",
        "output_layer = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Creating the Residual model\n",
        "m3 = models.Model(inputs=in_layer, outputs=output_layer)\n",
        "\n",
        "# Compiling the model\n",
        "m3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "m3.fit(x_train, Y_train, epochs=10, validation_data=(x_val, Y_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "W7ca7kkEP_MS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e3b8c78-b81e-47fa-9faa-96cc1175231b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 94ms/step - accuracy: 0.7522 - loss: 1.0520\n",
            "Test Accuracy for Residual Model : 75.20%\n",
            "Test Loss for Residual Model : 1.0623\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the Residual model\n",
        "t_loss, t_acc = m3.evaluate(x_test, Y_test)\n",
        "print(f\"Test Accuracy for Residual Model : {t_acc * 100:.2f}%\")\n",
        "print(f\"Test Loss for Residual Model : {t_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoXRF1ZNQSsi"
      },
      "source": [
        "# Part 5: Evaluation and Report Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CocNCJgYS5uG"
      },
      "source": [
        "1.    **Basic CNN Model**: The basic CNN model has three layers of convolution, max-pooling, and batch normalization, followed by dense layers for classification.\n",
        "\n",
        "*Test Set Results*\n",
        "* Test Accuracy: 67.30%\n",
        "* Test Loss: 1.2543\n",
        "\n",
        "*Analysis*\n",
        "\n",
        "* The basic CNN model achieves a test accuracy of 67.30%, which is a decent starting point for the CIFAR-10 dataset, known for its difficulty. The test loss of 1.2543 is relatively high, indicating that the model can be improved. Its simple design may not effectively capture the complex features of the diverse CIFAR-10 images, but it serves as a good baseline for comparison with more advanced models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_QwYV0HQdDk"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "2. **Inception Model**: This model uses an Inception block that combines multiple convolutional paths with different kernel sizes to capture features at various scales.\n",
        "\n",
        "*Test Set Results:*\n",
        "\n",
        "* Test Accuracy: 72.36%\n",
        "* Test Loss: 1.1665\n",
        "\n",
        "Analysis\n",
        "\n",
        "The Inception model shows better performance than the basic CNN, with a test accuracy of 72.36% and a lower test loss of 1.1665. Its ability to capture features at multiple scales contributes to this improvement. However, since it only has one Inception block, its potential for further enhancement is limited. Adding more Inception blocks or increasing the model’s depth could improve performance even more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZEHzFw2TA-q"
      },
      "source": [
        "\n",
        "3. **Residual Model**: This model uses residual blocks with skip connections, making it easier to train deeper networks.\n",
        "\n",
        "*Test Set Results*\n",
        "\n",
        "* Test Accuracy: 75.20%\n",
        "* Test Loss: 1.0623\n",
        "\n",
        "*Analysis*\n",
        "\n",
        "* The Residual model performs the best of the three, achieving a test accuracy of 75.20% and the lowest test loss of 1.0623. The use of residual connections helps improve gradient flow in deeper networks, contributing to its strong performance. The model can learn more complex features thanks to its deeper structure. However, there’s still room for improvement, such as by adding more residual blocks or tweaking the design."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJWDqY5XURwe"
      },
      "source": [
        "***Conclusion***\n",
        "\n",
        "* Basic CNN Model: Serves as a solid starting point with reasonable performance, but its simple architecture limits its ability to capture complex features.\n",
        "* Inception Model: Shows improved performance by effectively capturing features at multiple scales, though its potential could be further realized by adding more Inception blocks.\n",
        "* Residual Model: Achieves the best results, leveraging residual connections to enable effective training of a deeper network, although there is still potential for further enhancement through architectural tweaks."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}